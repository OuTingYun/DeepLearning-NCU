{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0402716f",
   "metadata": {
    "papermill": {
     "duration": 0.012224,
     "end_time": "2021-10-25T07:54:31.124970",
     "exception": false,
     "start_time": "2021-10-25T07:54:31.112746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1be0aae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T07:54:31.146655Z",
     "iopub.status.busy": "2021-10-25T07:54:31.145539Z",
     "iopub.status.idle": "2021-10-25T07:54:38.216023Z",
     "shell.execute_reply": "2021-10-25T07:54:38.215325Z",
     "shell.execute_reply.started": "2021-10-23T13:49:52.794978Z"
    },
    "id": "m23O-o9OWac-",
    "outputId": "5f251f97-af4d-4a45-be39-d93790f4eb9b",
    "papermill": {
     "duration": 7.082174,
     "end_time": "2021-10-25T07:54:38.216203",
     "exception": false,
     "start_time": "2021-10-25T07:54:31.134029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries I need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignore Deprecation Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning) \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential # intitialize the ANN\n",
    "from tensorflow.keras.layers import Dense      # create layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# load the data\n",
    "df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "df = df_train.append(df_test , ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "I use class to make easy to try different model and pre-rocessing, so it looks a little be wired.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA1(): \n",
    "    def __init__(self) -> None:\n",
    "        self.X_train, self.y_train,self.X_test=[],[],[]\n",
    "    #Data pre-processing  \n",
    "    def data_handle(self,df,df_train):\n",
    "        \n",
    "        # Processing Titleï¼šaccording to the passenger's name, dividing the passengers into five categories: Miss, Mrs, Master, Mr, Others \n",
    "        # and store these five categories as features in the data in the form of one-hot encoding.\n",
    "        df['Title'] = df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())\n",
    "        df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "        df['Title'] = df['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\n",
    "        df.Title.loc[ (df.Title !=  'Master') & (df.Title !=  'Mr') & (df.Title !=  'Miss') \n",
    "                    & (df.Title !=  'Mrs')] = 'Others'\n",
    "        df = pd.concat([df, pd.get_dummies(df['Title'])], axis=1).drop(labels=['Name'], axis=1)\n",
    "\n",
    "        # map the two genders to 0 and 1\n",
    "        df.Sex = df.Sex.map({'male':0, 'female':1})\n",
    "\n",
    "        # In revious analisis, the family Size is important feature to train. So here we create a new feature \"Family\" to store it.\n",
    "        df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df.Family = df.Family.map(lambda x: 0 if x > 4 else x)\n",
    "\n",
    "        # It is because that the value of ticket mix with text and number, \n",
    "        # so we get first character in ticket then classify iten 1-4 and S, P, C\n",
    "        df.Ticket = df.Ticket.map(lambda x: x[0])\n",
    "        guess_Fare = df.Fare.loc[ (df.Ticket == '3') & (df.Pclass == 3) & (df.Embarked == 'S')].median()\n",
    "        df.Fare.fillna(guess_Fare , inplace=True)\n",
    "        df['Fare-bin'] = pd.qcut(df.Fare,5,labels=[1,2,3,4,5]).astype(int)\n",
    "        df = df.drop(labels=['Cabin'], axis=1)  # delete the feature we don't really need\n",
    "        \n",
    "        # fill the NAN\n",
    "        df.Embarked.fillna('S' , inplace=True )\n",
    "        df = df.drop(labels='Embarked', axis=1)\n",
    "        \n",
    "        # notice that instead of using Title, we should use its corresponding dummy variables \n",
    "        df_sub = df[['Age','Master','Miss','Mr','Mrs','Others','Fare-bin','SibSp']]\n",
    "\n",
    "        self.X_train  = df_sub.dropna().drop('Age', axis=1) #X_train doesn't have Age column [1046,8]\n",
    "        self.y_train  = df['Age'].dropna() #[1046 17]\n",
    "        self.X_test = df_sub.loc[np.isnan(df.Age)].drop('Age', axis=1)\n",
    "\n",
    "        # predict the age to fill the NAN\n",
    "        regressor = RandomForestRegressor(n_estimators = 500) \n",
    "        regressor.fit(self.X_train, self.y_train)\n",
    "        y_pred = np.round(regressor.predict(self.X_test),1)\n",
    "        df.Age.loc[df.Age.isnull()] = y_pred\n",
    "\n",
    "        df.Age.isnull().sum(axis=0) # no more NAN now\n",
    "\n",
    "        bins = [ 0, 4, 12, 18, 30, 50, 65, 100] # This is somewhat arbitrary...\n",
    "        age_index = (1,2,3,4,5,6,7)\n",
    "        #('baby','child','teenager','young','mid-age','over-50','senior')\n",
    "        df['Age-bin'] = pd.cut(df.Age, bins, labels=age_index).astype(int)\n",
    "\n",
    "        df['Ticket'] = df['Ticket'].replace(['A','W','F','L','5','6','7','8','9'], '4')\n",
    "        # dummy encoding\n",
    "        df = pd.get_dummies(df,columns=['Ticket'])\n",
    "        df = df.drop(labels=['SibSp','Parch','Age','Fare','Title'], axis=1)\n",
    "\n",
    "        self.y_train = df[0:891]['Survived'].values\n",
    "        self.X_train = df[0:891].drop(['Survived','PassengerId'], axis=1).values\n",
    "        self.X_test  = df[891:].drop(['Survived','PassengerId'], axis=1).values \n",
    "        \n",
    "        \n",
    "    def Predict(self,model,batch_size):\n",
    "        x = model.predict(self.X_test,batch_size=batch_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def Opt_gen(self,lr = 0.01,momentum = 0.8,epochs = 10,opt_type = \"SGD\"):\n",
    "        if opt_type is \"SGD\":\n",
    "            print(\"SGD!\",end=\"\")\n",
    "            decay = lr / epochs\n",
    "            opt = keras.optimizers.SGD(learning_rate = lr, decay = decay, momentum = momentum, nesterov=False) \n",
    "        else:\n",
    "            print(opt_type,end=\"\")\n",
    "            return opt_type\n",
    "        return opt\n",
    "    def create_model(self,lyrs = [9,9,5], opt = \"Nadam\", activation = 'selu',lr=0.01,epochs=10,kernel_init = \"random_normal\",\n",
    "        base_init=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),X_train = df_train):\n",
    "            \n",
    "            base_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "            model = Sequential()\n",
    "            # First layer\n",
    "            model.add(Dense(lyrs[0],bias_initializer=base_init, kernel_initializer = kernel_init, activation = activation, input_dim = X_train.shape[1]))\n",
    "            \n",
    "            # layers\n",
    "            for i in range(1,len(lyrs)):\n",
    "                model.add(Dense(lyrs[i],bias_initializer=base_init, activation=activation,kernel_initializer = kernel_init))\n",
    "\n",
    "            # output layer\n",
    "            model.add(Dense(units = 1,bias_initializer=base_init, kernel_initializer = kernel_init, activation = 'sigmoid'))\n",
    "\n",
    "            optimizers = self.Opt_gen(lr=lr,opt_type=opt,epochs=epochs)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=optimizers, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            return model\n",
    "   \n",
    "Model=Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the picture after training\n",
    "def draw(history):\n",
    "    val_acc = np.mean(history.history['val_accuracy'])\n",
    "    print(\"\\n%s: %.2f%%\" % ('val_acc', val_acc*100))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation','loss','val_loss'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "My_data = EDA1()\n",
    "My_data.data_handle(df,df_train)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "stop = EarlyStopping(monitor='val_loss', patience = epochs, verbose = 1)\n",
    "\n",
    "### age\n",
    "model = Model.create_model(lr=0.001,activation=\"selu\",base_init=\"zero\",opt=\"SGD\",kernel_init=\"he_normal\",X_train=My_data.X_train)\n",
    "history = model.fit(My_data.X_train,My_data.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.33, shuffle = True,callbacks = [stop])\n",
    "draw(history)\n",
    "## Perdict\n",
    "prediction_reg=My_data.Predict(model,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae236f9",
   "metadata": {
    "papermill": {
     "duration": 0.008312,
     "end_time": "2021-10-25T07:54:38.276961",
     "exception": false,
     "start_time": "2021-10-25T07:54:38.268649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b861cecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T07:54:38.297089Z",
     "iopub.status.busy": "2021-10-25T07:54:38.296447Z",
     "iopub.status.idle": "2021-10-25T07:54:38.300894Z",
     "shell.execute_reply": "2021-10-25T07:54:38.301362Z",
     "shell.execute_reply.started": "2021-10-23T13:49:52.843557Z"
    },
    "id": "Sb6MPWDOWac_",
    "papermill": {
     "duration": 0.016134,
     "end_time": "2021-10-25T07:54:38.301546",
     "exception": false,
     "start_time": "2021-10-25T07:54:38.285412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save(prediction,name):\n",
    "    binarizer = Binarizer(threshold = 0.5)\n",
    "    prediction = binarizer.fit_transform(prediction)\n",
    "    prediction = prediction.astype(np.int32)                       \n",
    "    # create submission file\n",
    "    PassengerId = df_test[\"PassengerId\"]\n",
    "    evaluation = PassengerId.to_frame()\n",
    "    evaluation[\"Survived\"] = prediction\n",
    "    evaluation.to_csv(f\"{name}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295800f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T07:55:01.165544Z",
     "iopub.status.busy": "2021-10-25T07:55:01.164859Z",
     "iopub.status.idle": "2021-10-25T07:55:01.170896Z",
     "shell.execute_reply": "2021-10-25T07:55:01.171416Z",
     "shell.execute_reply.started": "2021-10-23T13:50:11.151051Z"
    },
    "id": "c4sSuyMLWadC",
    "papermill": {
     "duration": 0.093563,
     "end_time": "2021-10-25T07:55:01.171587",
     "exception": false,
     "start_time": "2021-10-25T07:55:01.078024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## save\n",
    "save(prediction_reg,\"submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV \n",
    "modelCV = KerasClassifier(build_fn=model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size_buf = [8]\n",
    "epochs_buf = [20]\n",
    "optimizer_buf = ['SGD', 'Adagrad', 'Adadelta', 'Adam', 'Nadam']\n",
    "# layers = [(9,9,5),(13,10,5)]\n",
    "activation = ['softmax', 'softplus', 'relu', 'tanh','selu']\n",
    "param_grid = dict(batch_size=batch_size_buf, epochs=epochs_buf,opt=optimizer_buf,activation=activation) \n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=modelCV, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=2)  # include n_jobs=-1 if you are using CPU\n",
    "\n",
    "grid_result = grid.fit(My_data.X_train, My_data.y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.59767,
   "end_time": "2021-10-25T07:55:04.466299",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-25T07:54:22.868629",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
