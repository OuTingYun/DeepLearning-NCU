{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational imports\n",
    "import numpy as np   # Library for n-dimensional arrays\n",
    "import pandas as pd  # Library for dataframes (structured data)\n",
    "\n",
    "# Helper imports\n",
    "import os \n",
    "import warnings\n",
    "# import pandas_datareader as web\n",
    "import datetime as dt\n",
    "\n",
    "# ML/DL imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed,GRU,Embedding\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.figure_factory as ff\n",
    "# from plotly.subplots import make_subplots\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "# Set seeds to make the experiment more reproducible.\n",
    "from numpy.random import seed\n",
    "import json\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='model2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "test_data = pd.read_csv('test.csv', index_col=0)\n",
    "data_oil = pd.read_csv('oil.csv')\n",
    "samp_subm = pd.read_csv('sample_submission.csv')\n",
    "data_holi = pd.read_csv('holidays_events.csv')\n",
    "data_store =  pd.read_csv('stores.csv')\n",
    "data_trans = pd.read_csv('transactions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## holiday 重複的部分做處理\n",
    "#  type：{'holiday':3,'transfer':4,'addition:'0','bridge':1,'work day':5,'event':2} nan=6\n",
    "#  local:{'local':0,'region':2,'nation':1} nan=3\n",
    "data_holi = data_holi[['date','type','locale']]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "c = ['type','locale']\n",
    "data_holi[c] = ordinal_encoder.fit_transform(data_holi[c])\n",
    "data_holi[c]=data_holi[c].astype(int)\n",
    "data_holi = data_holi.groupby(['date'],as_index=False).agg({'type':'mean','locale':'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_data,test_data],ignore_index=True)\n",
    "all_data['date'] =  pd.to_datetime(all_data['date'])\n",
    "data_holi['date'] = pd.to_datetime(data_holi['date'])\n",
    "data_oil['date'] = pd.to_datetime(data_oil['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = all_data.merge(data_holi, on = 'date', how='left')\n",
    "df_train1 = df_train1.merge(data_oil, on = 'date', how='left')\n",
    "df_train1 = df_train1.merge(data_store, on = 'store_nbr', how='left')\n",
    "df_train1 = df_train1.rename(columns = {\"type_x\" : \"holiday_type\", \"type_y\" : \"store_type\"})\n",
    "df_train1['day_of_week'] = df_train1['date'].dt.day_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['year'] = df['date'].dt.year\n",
    "# df['month'] = df['date'].dt.month\n",
    "# df['week'] = df['date'].dt.isocalendar().week\n",
    "# df['quarter'] = df['date'].dt.quarter\n",
    "\n",
    "\n",
    "train_columns = ['date','store_nbr','family','sales','onpromotion','holiday_type','locale','dcoilwtico','store_type','cluster','day_of_week']\n",
    "df = df_train1[train_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test,num_train = len(test_data),len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "df = train + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圖示化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# buf = df[['date','store_nbr','sales','family']].groupby(['store_nbr','family','date'],as_index = False).agg({\"sales\":\"mean\"})\n",
    "# store = []\n",
    "# for i in range(1,55):\n",
    "#     f = list(buf[buf['store_nbr']==i].drop(columns = ['store_nbr']).groupby(['family']))\n",
    "#     store1 = f[0][1].drop(columns=['family'])\n",
    "#     for i in range(1,33):\n",
    "#         store1 = store1.merge(f[i][1].drop(columns=['family']), on = 'date', how='left')\n",
    "#         store1 = store1.rename(columns = {\"sales_x\": \"sales\" ,\"sales_y\" : f[i][0]})\n",
    "#     store1 = store1.rename(columns = {\"sales\": f[0][0]})  \n",
    "#     store.append(store1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday_type'].fillna(6,inplace=True)\n",
    "df['locale'].fillna(3,inplace=True)\n",
    "df['dcoilwtico'].fillna(df['dcoilwtico'].mean(),inplace=True)\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['family', 'store_type', 'day_of_week'] ['store_nbr', 'sales', 'onpromotion', 'holiday_type', 'locale', 'dcoilwtico', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "object_cols = [cname for cname in df.columns if df[cname].dtype == \"object\"]\n",
    "number_cols = [cname for cname in df.columns if df[cname].dtype!=\"object\" and cname!='date']\n",
    "# buf[col] = ordinal_encoder.fit_transform(buf[col])\n",
    "print(object_cols,number_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "df[object_cols] = ordinal_encoder.fit_transform(df[object_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition ={\n",
    "    'store_nbr':'mean',#(都一樣)\n",
    "    'family':'mean',#(都一樣)\n",
    "    'onpromotion':'mean',\n",
    "    'holiday_type':'mean', #ok\n",
    "    'locale':'mean',#ok\n",
    "    'dcoilwtico':'mean',#ok\n",
    "    'store_type':'mean',#(都一樣)\n",
    "    'cluster':'mean',\n",
    "    'day_of_week':'mean'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df[:num_train].copy()\n",
    "train_condition = condition.copy()\n",
    "train_condition['sales'] ='mean'\n",
    "train_x = train_x.groupby(['date'],as_index=False).agg(train_condition)#ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_buf = pd.DataFrame()\n",
    "# for i in range(0,33):\n",
    "#     f = df[df['family']==i]\n",
    "#     f[\"sales\"] = scaler.fit_transform(f[\"sales\"].values.reshape(-1,1))\n",
    "#     new_buf = pd.concat([new_buf,f],axis=0)\n",
    "# df = new_buf.sort_index()\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for col in number_cols+object_cols:\n",
    "    # if col==\"sales\":continue\n",
    "    df[col] = scaler.fit_transform(df[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ProjectPy37\\lib\\site-packages\\pandas\\core\\frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_y = train_x[['date','sales']]\n",
    "train_x.drop(columns=['date','sales'],inplace=True)\n",
    "train_y.drop(columns=['date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_input = 7\n",
    "train_input = []\n",
    "train_output = []\n",
    "for i in range(len(train_x)-history_input+1):\n",
    "    train_input.append(train_x[i:i+history_input].values)\n",
    "    train_output.append(train_y.iloc[i+history_input-1])\n",
    "train_input=np.array(train_input)\n",
    "train_output=np.array(train_output)\n",
    "# print(x_train_input.shape)\n",
    "# print(y_train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Make_Model_GRU():    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multi_Step_LSTM_model():\n",
    "    \n",
    "    # Use Keras sequential model\n",
    "    model = Sequential()    \n",
    "    \n",
    "    # First LSTM layer with Dropout regularisation; Set return_sequences to True to feed outputs to next layer\n",
    "    model.add(LSTM(units = 50, activation='relu', return_sequences = True, input_shape = train_input[0].shape )) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second LSTM layer with Dropout regularisation; Set return_sequences to True to feed outputs to next layer\n",
    "    model.add(LSTM(units = 50,  activation='relu', return_sequences = True))                                    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Final LSTM layer with Dropout regularisation; Set return_sequences to False since now we will be predicting with the output layer\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # The output layer with linear activation to predict Open stock price\n",
    "    model.add(Dense(units=1, activation = \"linear\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 7, 50)             12000     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 50)             20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 52,451\n",
      "Trainable params: 52,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 111146.3438 - accuracy: 0.0000e+00 - val_loss: 223401.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 110931.2422 - accuracy: 0.0000e+00 - val_loss: 223241.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 110802.6250 - accuracy: 0.0000e+00 - val_loss: 223105.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 110640.4922 - accuracy: 0.0000e+00 - val_loss: 222963.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 110498.7266 - accuracy: 0.0000e+00 - val_loss: 222803.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 110386.9062 - accuracy: 0.0000e+00 - val_loss: 222576.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 110212.9844 - accuracy: 0.0000e+00 - val_loss: 222252.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 110083.5234 - accuracy: 0.0000e+00 - val_loss: 221970.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 109962.4297 - accuracy: 0.0000e+00 - val_loss: 221747.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 109816.3359 - accuracy: 0.0000e+00 - val_loss: 221532.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 109668.5469 - accuracy: 0.0000e+00 - val_loss: 221301.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 109519.0859 - accuracy: 0.0000e+00 - val_loss: 221058.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 109382.2109 - accuracy: 0.0000e+00 - val_loss: 220812.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 109242.4375 - accuracy: 0.0000e+00 - val_loss: 220577.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 109108.2578 - accuracy: 0.0000e+00 - val_loss: 220354.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 108949.3594 - accuracy: 0.0000e+00 - val_loss: 220143.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 108801.0781 - accuracy: 0.0000e+00 - val_loss: 219935.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 108670.6953 - accuracy: 0.0000e+00 - val_loss: 219720.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 108507.5781 - accuracy: 0.0000e+00 - val_loss: 219522.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 108361.2344 - accuracy: 0.0000e+00 - val_loss: 219356.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 108231.6797 - accuracy: 0.0000e+00 - val_loss: 219189.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 108071.1875 - accuracy: 0.0000e+00 - val_loss: 218965.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 107916.7031 - accuracy: 0.0000e+00 - val_loss: 218662.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 107764.9688 - accuracy: 0.0000e+00 - val_loss: 218353.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 107593.3750 - accuracy: 0.0000e+00 - val_loss: 218129.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 107428.9844 - accuracy: 0.0000e+00 - val_loss: 217988.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 107320.6719 - accuracy: 0.0000e+00 - val_loss: 217865.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 107202.6094 - accuracy: 0.0000e+00 - val_loss: 217742.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 107064.3203 - accuracy: 0.0000e+00 - val_loss: 217622.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 106924.1172 - accuracy: 0.0000e+00 - val_loss: 217499.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 106782.7266 - accuracy: 0.0000e+00 - val_loss: 217353.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 106672.5156 - accuracy: 0.0000e+00 - val_loss: 217181.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 106579.3359 - accuracy: 0.0000e+00 - val_loss: 217009.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 106469.0625 - accuracy: 0.0000e+00 - val_loss: 216863.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 106370.1094 - accuracy: 0.0000e+00 - val_loss: 216742.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 106295.7578 - accuracy: 0.0000e+00 - val_loss: 216644.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 106173.3984 - accuracy: 0.0000e+00 - val_loss: 216562.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 106101.4062 - accuracy: 0.0000e+00 - val_loss: 216482.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 106032.7266 - accuracy: 0.0000e+00 - val_loss: 216387.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 105990.4141 - accuracy: 0.0000e+00 - val_loss: 216267.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 105920.8281 - accuracy: 0.0000e+00 - val_loss: 216132.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 105806.4609 - accuracy: 0.0000e+00 - val_loss: 216014.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 105765.8047 - accuracy: 0.0000e+00 - val_loss: 215927.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 105724.9844 - accuracy: 0.0000e+00 - val_loss: 215857.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 105649.4531 - accuracy: 0.0000e+00 - val_loss: 215787.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 105607.4531 - accuracy: 0.0000e+00 - val_loss: 215707.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 105545.4141 - accuracy: 0.0000e+00 - val_loss: 215610.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 105496.8281 - accuracy: 0.0000e+00 - val_loss: 215496.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 105423.6562 - accuracy: 0.0000e+00 - val_loss: 215372.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 105390.3750 - accuracy: 0.0000e+00 - val_loss: 215256.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 105263.6562 - accuracy: 0.0000e+00 - val_loss: 215153.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 105209.4688 - accuracy: 0.0000e+00 - val_loss: 215063.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 105156.7812 - accuracy: 0.0000e+00 - val_loss: 214984.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 105059.5703 - accuracy: 0.0000e+00 - val_loss: 214905.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 105012.6875 - accuracy: 0.0000e+00 - val_loss: 214813.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 104923.9062 - accuracy: 0.0000e+00 - val_loss: 214715.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 104874.1719 - accuracy: 0.0000e+00 - val_loss: 214618.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 104782.9375 - accuracy: 0.0000e+00 - val_loss: 214516.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 104751.6172 - accuracy: 0.0000e+00 - val_loss: 214405.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 104670.6406 - accuracy: 0.0000e+00 - val_loss: 214300.4844 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 104603.2891 - accuracy: 0.0000e+00 - val_loss: 214227.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 104574.7109 - accuracy: 0.0000e+00 - val_loss: 214170.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 104512.8750 - accuracy: 0.0000e+00 - val_loss: 214116.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 104459.3594 - accuracy: 0.0000e+00 - val_loss: 214063.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 104419.7188 - accuracy: 0.0000e+00 - val_loss: 214011.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 104372.1250 - accuracy: 0.0000e+00 - val_loss: 213958.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 104348.9844 - accuracy: 0.0000e+00 - val_loss: 213906.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 104314.1484 - accuracy: 0.0000e+00 - val_loss: 213853.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 104269.3125 - accuracy: 0.0000e+00 - val_loss: 213801.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 104203.3828 - accuracy: 0.0000e+00 - val_loss: 213749.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 104165.8672 - accuracy: 0.0000e+00 - val_loss: 213697.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 104150.6250 - accuracy: 0.0000e+00 - val_loss: 213645.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 104095.6016 - accuracy: 0.0000e+00 - val_loss: 213593.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 104088.5469 - accuracy: 0.0000e+00 - val_loss: 213542.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 104054.0234 - accuracy: 0.0000e+00 - val_loss: 213490.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 104037.5781 - accuracy: 0.0000e+00 - val_loss: 213439.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 103971.9609 - accuracy: 0.0000e+00 - val_loss: 213387.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 103905.6250 - accuracy: 0.0000e+00 - val_loss: 213336.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 103928.7734 - accuracy: 0.0000e+00 - val_loss: 213285.6562 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 103820.0703 - accuracy: 0.0000e+00 - val_loss: 213234.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 103840.2891 - accuracy: 0.0000e+00 - val_loss: 213183.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 103768.2969 - accuracy: 0.0000e+00 - val_loss: 213133.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 103775.1562 - accuracy: 0.0000e+00 - val_loss: 213082.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 103753.2031 - accuracy: 0.0000e+00 - val_loss: 213032.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 103734.6875 - accuracy: 0.0000e+00 - val_loss: 212982.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 103656.1797 - accuracy: 0.0000e+00 - val_loss: 212931.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 103647.1719 - accuracy: 0.0000e+00 - val_loss: 212881.9531 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 103570.8438 - accuracy: 0.0000e+00 - val_loss: 212832.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 103550.7188 - accuracy: 0.0000e+00 - val_loss: 212782.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 103527.8047 - accuracy: 0.0000e+00 - val_loss: 212732.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 103510.6562 - accuracy: 0.0000e+00 - val_loss: 212682.9844 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 103496.8281 - accuracy: 0.0000e+00 - val_loss: 212633.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 103429.2734 - accuracy: 0.0000e+00 - val_loss: 212584.1719 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 103380.0312 - accuracy: 0.0000e+00 - val_loss: 212534.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 103362.4062 - accuracy: 0.0000e+00 - val_loss: 212485.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 103355.8828 - accuracy: 0.0000e+00 - val_loss: 212436.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 103318.3359 - accuracy: 0.0000e+00 - val_loss: 212387.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 103286.2344 - accuracy: 0.0000e+00 - val_loss: 212338.9844 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 103265.7188 - accuracy: 0.0000e+00 - val_loss: 212290.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 103180.3203 - accuracy: 0.0000e+00 - val_loss: 212241.6250 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Multi_Step_LSTM_model()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5,verbose=2)\n",
    "history = model.fit(train_input,train_output, validation_split=0.3,batch_size=len(train_input), epochs=100,callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAstklEQVR4nO3de5hU1Z3u8e+vLn1DlIuKAk7AiQIKKtgiOYSJSsZBvKCOiIk3jJEJmlHzJDlhPJmjccwc8zzGyWUUo8breCMYlMloGDUQ40SNoERRUdGgNN5Q5N63qvqdP/aq6uqmgQJ2d9PV7+d56qm9176t3aX1stbatbe5OyIiInFKdHUFRESk/ChcREQkdgoXERGJncJFRERip3AREZHYKVxERCR2CheRGJjZXWZ2XYnrrjSzL3d0nUS6ksJFRERip3ARkQIzS3V1HaQ8KFykxwjdUd81s5fNbLOZ/dLMBpjZ42a20cyeNLO+ReufZmavmtk6M1tkZiOKlo02sxfDdg8BVW2OdYqZLQ3b/tHMjiixjieb2UtmtsHMVpnZNW2WfzHsb11YPj2UV5vZj83sXTNbb2bPhLLjzKyunb/Dl8P0NWY218z+w8w2ANPNbKyZPRuO8YGZ/buZVRRtf7iZPWFma83sIzO7yswOMLMtZta/aL0xZrbGzNKlnLuUF4WL9DR/D/wtcChwKvA4cBWwH9H/D5cDmNmhwAPAlWHZY8B/mllF+KJ9BLgX6Af8KuyXsO1o4A7gH4D+wC+A+WZWWUL9NgMXAH2Ak4GZZnZ62O/nQn1/Hup0FLA0bHcDcDTwv0Kd/jeQK/FvMgWYG455H5AFvgXsC3wBmAhcGurQG3gS+C0wEPg88JS7fwgsAs4u2u/5wIPu3lxiPaSMKFykp/m5u3/k7quBPwDPu/tL7t4AzANGh/WmAf/l7k+EL8cbgGqiL+9xQBr4ibs3u/tc4IWiY8wAfuHuz7t71t3vBhrDdtvl7ovc/RV3z7n7y0QB96Ww+KvAk+7+QDjup+6+1MwSwNeAK9x9dTjmH929scS/ybPu/kg4Zr27L3H359w94+4ricIxX4dTgA/d/cfu3uDuG939+bDsbuA8ADNLAl8hCmDpgRQu0tN8VDRd3878XmF6IPBufoG754BVwKCwbLW3vuvru0XTnwO+HbqV1pnZOuCgsN12mdmxZrYwdCetB75B1IIg7OPtdjbbl6hbrr1lpVjVpg6HmtlvzOzD0FX2ryXUAeBR4DAzG0rUOlzv7n/axTpJN6dwEWnf+0QhAYCZGdEX62rgA2BQKMv7q6LpVcAP3b1P0avG3R8o4bj3A/OBg9x9H+AWIH+cVcBft7PNJ0DDNpZtBmqKziNJ1KVWrO2t0WcDy4FD3H1vom7D4joc3F7FQ+tvDlHr5XzUaunRFC4i7ZsDnGxmE8OA9LeJurb+CDwLZIDLzSxtZmcCY4u2vQ34RmiFmJn1CgP1vUs4bm9grbs3mNlYoq6wvPuAL5vZ2WaWMrP+ZnZUaFXdAdxoZgPNLGlmXwhjPG8CVeH4aeD7wI7GfnoDG4BNZjYcmFm07DfAgWZ2pZlVmllvMzu2aPk9wHTgNBQuPZrCRaQd7v4G0b/Af07UMjgVONXdm9y9CTiT6Et0LdH4zK+Ltl0MXAL8O/AZsCKsW4pLgWvNbCPwf4lCLr/f94DJREG3lmgw/8iw+DvAK0RjP2uBHwEJd18f9nk7UatrM9Dq6rF2fIco1DYSBeVDRXXYSNTldSrwIfAWcHzR8v8hupDgRXcv7iqUHsb0sDARiZOZ/Q64391v7+q6SNdRuIhIbMzsGOAJojGjjV1dH+k66hYTkViY2d1Ev4G5UsEiarmIiEjs1HIREZHY6SZ1wb777utDhgzp6mqIiHQrS5Ys+cTd2/52SuGSN2TIEBYvXtzV1RAR6VbMrN1LztUtJiIisVO4iIhI7BQuIiISO425bEdzczN1dXU0NDR0dVXKQlVVFYMHDyad1rOjRMqdwmU76urq6N27N0OGDKH1DXBlZ7k7n376KXV1dQwdOrSrqyMiHUzdYtvR0NBA//79FSwxMDP69++vVqBID6Fw2QEFS3z0txTpOdQttpuyGzaQa2jAEgkILzMrmk5AIprPr2MJZbqIlDeFy27KbdpEZu3andvIDEskIZnAkkkslYJUCgsvQtn6jRt54Fe/4tJLL43KSvyX/+TJk7n//vvp06fPzp+QiEgMFC67KT1wIKkDD4RcDs/lILzcvWW6UO5hOotn8+9ZvLkZr6/HM5lW+/549Wpu/vnP+doJJwBELZ5kkqw7qYpKLJWMQifZ8m7JJP85Zw6WTJJraoqW5VtTIiKdROESAzNr+ZLfDe4O2SyeyeDZLFdffTXv1NUx7pxzSKdSVFVW0mfvvXnj7bdZ9uSTnPW1r1H3wQc0NDZy6bnncvHUqQAM/7u/45kHH2Tzli2cPnMmXxgzhueXLmXgAQcw95ZfUN2rpiWQQmAV3pNJSCSxZOjCC+GEmQJKREqmcCnRD/7zVV57f0Os+zxs4N5cferhhXkzK3SPAfzoxz/m1Tfe4M/LlrFo0SJOPvlkli1bVriU9645c+jXrx/19fUcc8wxTJs5k/59+mCpFBWDB9O4YQMr3nuPe2+7jVtHjOArM2Yw74n/5qtTpuCNjS2tp1xux5U1az2uVAil0L2XSmHJFKSShe69QhefQkmkx1G4dCNjx45t9RuRn/3sZ8ybNw+AVatW8fbKlew3bhyYkezdm5QZQ4cO5ZiJEwE4ZsIEVm/eTOXBB7fab6HFlMtF79ls1J2Xf89362Vbpj2XhWyWXHNzaG1lgfafDVQcRJk1a3j3+h9hVZUkKqta3quriuYrsfx0VRVWWUmiujqarq4hUVNNolcvEjU1JGpqdrvFKCLxU7iUqLiF0VV69epVmF60aBFPPvkkzz77LDU1NRx33HHt/oaksrKyMJ1MJqmvr99qnUKLaTfq1qpLL5OFbAZvzoSAagksEgk8kyG3ZiPNjY14QwO5oneam3f62FZdHQVNr15RCFVXk6ipxqqqscqKKLQqK7GKCqwiHb2n0+28WpYnKiqwyioSVZXR/quqsKrqaL6qKtqHWmQi26Rw2YP17t2bjRvbf1rs+vXr6du3LzU1NSxfvpznnnuuk2vXWtsuvW1Jbd7MkPv+Y5vLPZttHTgNjXhjA7n6Bryhnlx9Pbkt9eS2bCG3eXP0Kp5uaMDrt0TrfLYu7KsBb2zCm1pexPAEVqusbB1OqRSWTkM6haVa5ouXRQFXEW1bWUGiIoRVZQWJqurWLbfKiijU0hVYZUVL6IV90jYUUyld5i57DIXLHqx///6MHz+ekSNHUl1dzYABAwrLJk2axC233MKIESMYNmwY48aN68KaxseSSaxXLxJFrbSO4NlsFDSZTHS1XlNTy3tTE97YSK6xqSXYigMuH3iNjdE24UVzpmV/mQyeaSnPbd5MrrkJmpvJNTVFYdfYGI7TCNlsPCfWKsTSJNJFYZYPtop0FGrFIVdZiVVUFoVeFGLRPxhCcKWSkMyPpSWwZKroisWi6VQqXDCSii4MaVuWCheOhLL8xSW6qrG8mMfwL7hyUFtb620fFvb6668zYsSILqpRedLftH3e3FxoreUDxxsa8KamKOSamvDmotZXPtSamlvCrDgci6ZzTY3RekXBmd9frk3IeWNj1H3ZVdoEzlYhlG+dpUKgbbMsXGxSYpmlwlWSbcOyTVmrUC1sl9gqPAtliURRWbJ1sLZaVrR+YV/d42IYM1vi7rVty9VyEdkDWDpNMp2Gvfbq6qpEQdXYGFpf0Yuiac9mWy7iKPxWKxNNZ7J4pjm66KN4Or9Ncya6GCQTjc+1bJMp/P7LM83RxSPZMHaXzeHZTNQyzOWiskx2m/uJroQM5dmwXtjWs5lom1yu5ZyKL2Rp81uzLpf/OcBWwRNCLl9WFK5bLStav7AsGYItLOt/8cVUDRsWa9UVLiLSipUwdlbO2g2e4lAteo+CLVcIJs+G8CteLx/CmWwUbsXBm821hGRuG+sXB21xqOb3n8u1v6/idZqbyWW3tFwVmmkOdY3WyU2N92cWoHAREWnFEgkI41Oy63RpiYiIxE7hIiIisVO4iIhI7BQuZWSvcKXR+++/z1lnndXuOscddxxtL7lu6yc/+QlbtmwpzE+ePJl169bFVk8RKX8KlzI0cOBA5s6du8vbtw2Xxx57TM+GEZGdonDZg82aNYubbrqpMH/NNddw3XXXMXHiRMaMGcOoUaN49NFHt9pu5cqVjBw5EoD6+nrOOeccRowYwRlnnNHq3mIzZ86ktraWww8/nKuvvhqIbob5/vvvc/zxx3P88ccDMGTIED755BMAbrzxRkaOHMnIkSP5yU9+UjjeiBEjuOSSSzj88MM58cQT272HmYj0HB12KbKZHQTcAwwgul3ure7+UzPrBzwEDAFWAme7+2cW/RT1p8BkYAsw3d1fDPu6EPh+2PV17n53KD8auAuoBh4DrnB339YxduuEHp8FH76yW7vYygGj4KTrt7l42rRpXHnllVx22WUAzJkzhwULFnD55Zez995788knnzBu3DhOO+20bf6Sd/bs2dTU1PD666/z8ssvM2bMmMKyH/7wh/Tr149sNsvEiRN5+eWXufzyy7nxxhtZuHAh++67b6t9LVmyhDvvvJPnn38ed+fYY4/lS1/6En379uWtt97igQce4LbbbuPss8/m4Ycf5rzzzovhjyQi3VFHtlwywLfd/TBgHHCZmR0GzAKecvdDgKfCPMBJwCHhNQOYDRCC4mrgWGAscLWZ9Q3bzAYuKdpuUijf1jG6ldGjR/Pxxx/z/vvv8+c//5m+fftywAEHcNVVV3HEEUfw5S9/mdWrV/PRRx9tcx9PP/104Uv+iCOO4IgjjigsmzNnDmPGjGH06NG8+uqrvPbaa9utzzPPPMMZZ5xBr1692GuvvTjzzDP5wx/+AMDQoUM56qijADj66KNZuXLl7p28iHRrHdZycfcPgA/C9EYzex0YBEwBjgur3Q0sAr4Xyu/x6GZnz5lZHzM7MKz7hLuvBTCzJ4BJZrYI2Nvdnwvl9wCnA49v5xi7bjstjI40depU5s6dy4cffsi0adO47777WLNmDUuWLCGdTjNkyJB2b7W/I3/5y1+44YYbeOGFF+jbty/Tp0/fpf3klXJrfxHpOTplzMXMhgCjgeeBASF4AD4k6jaDKHhWFW1WF8q2V17XTjnbOUbbes0ws8VmtnjNmjW7cGYdb9q0aTz44IPMnTuXqVOnsn79evbff3/S6TQLFy7k3Xff3e72f/M3f8P9998PwLJly3j55ZcB2LBhA7169WKfffbho48+4vHHHy9ss61b/U+YMIFHHnmELVu2sHnzZubNm8eECRNiPFsRKRcdfvsXM9sLeBi40t03FI8NhPGRDr0t8/aO4e63ArdCdFfkjqzHrjr88MPZuHEjgwYN4sADD+Tcc8/l1FNPZdSoUdTW1jJ8+PDtbj9z5kwuuugiRowYwYgRIzj66KMBOPLIIxk9ejTDhw/noIMOYvz48YVtZsyYwaRJkxg4cCALFy4slI8ZM4bp06czduxYAL7+9a8zevRodYGJyFY69Jb7ZpYGfgMscPcbQ9kbwHHu/kHo9lrk7sPM7Bdh+oHi9fIvd/+HUP4Lom6uRcBCdx8eyr+SX29bx9heXXXL/c6hv6lIednWLfc7rFssXP31S+D1fLAE84ELw/SFwKNF5RdYZBywPnRtLQBONLO+YSD/RKKw+gDYYGbjwrEuaLOv9o4hIiKdoCO7xcYD5wOvmNnSUHYVcD0wx8wuBt4Fzg7LHiO6DHkF0aXIFwG4+1oz+xfghbDetfnBfeBSWi5Ffjy82M4xRESkE3Tk1WLPANt6jNrEdtZ34LJt7OsO4I52yhcDI9sp/7S9Y4iISOfQL/RFRCR2ChcREYmdwkVERGKncBERkdgpXPZg69at4+abb97p7Xb1+SvTp0/frVv1i4jkKVz2YNsKl0wms93t9PwVEelqHX77l3Lxoz/9iOVrl8e6z+H9hvO9sdu+n+asWbN4++23Oeqoo0in01RVVdG3b1+WL1/Om2++yemnn86qVatoaGjgiiuuYMaMGUD0/JXFixezadMmTjrpJL74xS/yxz/+kUGDBvHoo49SXV29w7o99dRTfOc73yGTyXDMMccwe/ZsKisrmTVrFvPnzyeVSnHiiSdyww038Ktf/Yof/OAHJJNJ9tlnH55++unY/kYi0j0pXPZg119/PcuWLWPp0qUsWrSIk08+mWXLljF06FAA7rjjDvr160d9fT3HHHMMf//3f0///v1b7WNXnrPS0NDA9OnTeeqppzj00EO54IILmD17Nueffz7z5s1j+fLlmFmh6+3aa69lwYIFDBo0SI9DFhFA4VKy7bUwOsvYsWMLwQLRUyPnzZsHwKpVq3jrrbe2Cpddec7KG2+8wdChQzn00EMBuPDCC7npppv45je/SVVVFRdffDGnnHIKp5xyCgDjx49n+vTpnH322Zx55pkxnKmIdHcac+lGevXqVZhetGgRTz75JM8++yx//vOfGT16dLvPY2n7nJUdjddsTyqV4k9/+hNnnXUWv/nNb5g0KXo22y233MJ1113HqlWrOProo/n00093+RgiUh7UctmDbeu5KgDr16+nb9++1NTUsHz5cp577rnYjjts2DBWrlzJihUr+PznP8+9997Ll770JTZt2sSWLVuYPHky48eP5+CDDwbg7bff5thjj+XYY4/l8ccfZ9WqVVu1oESkZ1G47MH69+/P+PHjGTlyJNXV1QwY0PLMs0mTJnHLLbcwYsQIhg0bxrhx42I7blVVFXfeeSdTp04tDOh/4xvfYO3atUyZMoWGhgbcnRtvjG52/d3vfpe33noLd2fixIkceeSRsdVFRLqnDn2eS3ei57l0Dv1NRcpLpz/PRUREei51i/VAl112Gf/zP//TquyKK67goosu6qIaiUi5Ubj0QDfddFNXV0FEypy6xUREJHYKFxERiZ3CRUREYqdwERGR2Clcyshee+21zWUrV65k5MiRnVgbEenJFC4iIhI7XYpcog//9V9pfD3e57lUjhjOAVddtc3ls2bN4qCDDuKyyy4D4JprriGVSrFw4UI+++wzmpubue6665gyZcpOHbehoYGZM2eyePFiUqkUN954I8cffzyvvvoqF110EU1NTeRyOR5++GEGDhzI2WefTV1dHdlsln/+539m2rRpu3XeIlL+FC57sGnTpnHllVcWwmXOnDksWLCAyy+/nL333ptPPvmEcePGcdppp2FmJe/3pptuwsx45ZVXWL58OSeeeCJvvvkmt9xyC1dccQXnnnsuTU1NZLNZHnvsMQYOHMh//dd/AdENM0VEdkThUqLttTA6yujRo/n44495//33WbNmDX379uWAAw7gW9/6Fk8//TSJRILVq1fz0UcfccABB5S832eeeYZ//Md/BGD48OF87nOf48033+QLX/gCP/zhD6mrq+PMM8/kkEMOYdSoUXz729/me9/7HqeccgoTJkzoqNMVkTKiMZc93NSpU5k7dy4PPfQQ06ZN47777mPNmjUsWbKEpUuXMmDAgHaf47IrvvrVrzJ//nyqq6uZPHkyv/vd7zj00EN58cUXGTVqFN///ve59tprYzmWiJQ3tVz2cNOmTeOSSy7hk08+4fe//z1z5sxh//33J51Os3DhQt59992d3ueECRO47777OOGEE3jzzTd57733GDZsGO+88w4HH3wwl19+Oe+99x4vv/wyw4cPp1+/fpx33nn06dOH22+/vQPOUkTKjcJlD3f44YezceNGBg0axIEHHsi5557LqaeeyqhRo6itrWX48OE7vc9LL72UmTNnMmrUKFKpFHfddReVlZXMmTOHe++9l3Q6zQEHHMBVV13FCy+8wHe/+10SiQTpdJrZs2d3wFmKSLnR81wCPc+lc+hvKlJe9DwXERHpNOoWKzOvvPIK559/fquyyspKnn/++S6qkYj0RAqXHXD3nfoNSVcbNWoUS5cu7epqtEtdsCI9h7rFtqOqqopPP/1UX4oxcHc+/fRTqqqquroqItIJ1HLZjsGDB1NXV8eaNWu6uiploaqqisGDB3d1NUSkEyhctiOdTjN06NCuroaISLfTYd1iZnaHmX1sZsuKyq4xs9VmtjS8Jhct+yczW2Fmb5jZ3xWVTwplK8xsVlH5UDN7PpQ/ZGYVobwyzK8Iy4d01DmKiEj7OnLM5S5gUjvl/+buR4XXYwBmdhhwDnB42OZmM0uaWRK4CTgJOAz4SlgX4EdhX58HPgMuDuUXA5+F8n8L64mISCfqsHBx96eBtSWuPgV40N0b3f0vwApgbHitcPd33L0JeBCYYtHlWycAc8P2dwOnF+3r7jA9F5ho3elyLxGRMtAVV4t908xeDt1mfUPZIGBV0Tp1oWxb5f2Bde6eaVPeal9h+fqw/lbMbIaZLTazxRq0FxGJT2eHy2zgr4GjgA+AH3fy8Vtx91vdvdbda/fbb7+urIqISFnp1HBx94/cPevuOeA2om4vgNXAQUWrDg5l2yr/FOhjZqk25a32FZbvE9YXEZFO0qnhYmYHFs2eAeSvJJsPnBOu9BoKHAL8CXgBOCRcGVZBNOg/36NfNS4EzgrbXwg8WrSvC8P0WcDvXL+CFBHpVB32OxczewA4DtjXzOqAq4HjzOwowIGVwD8AuPurZjYHeA3IAJe5ezbs55vAAiAJ3OHur4ZDfA940MyuA14CfhnKfwnca2YriC4oOKejzlFERNqnW+4H7d1yX0REtk+33BcRkU6jcBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2ClcREQkdgoXERGJXUnhYma/NrOTzUxhJCIiO1RqWNwMfBV4y8yuN7NhHVgnERHp5koKF3d/0t3PBcYQ3RPsSTP7o5ldZGbpjqygiIh0PyV3c5lZf2A68HWiG0X+lChsnuiQmomISLdV0l2RzWweMAy4FzjV3T8Iix4yM93tUUREWin1lvs/c/eF7S1o726YIiLSs5XaLXaYmfXJz5hZXzO7tGOqJCIi3V2p4XKJu6/Lz7j7Z8AlHVIjERHp9koNl6SZWX7GzJJARcdUSUREurtSx1x+SzR4/4sw/w+hTEREZCulhsv3iAJlZph/Ari9Q2okIiLdXknh4u45YHZ4iYiIbFepv3M5BPh/wGFAVb7c3Q/uoHqJiEg3VuqA/p1ErZYMcDxwD/AfHVUpERHp3koNl2p3fwowd3/X3a8BTu64aomISHdW6oB+Y7jd/ltm9k1gNbBXx1VLRES6s1JbLlcANcDlwNHAecCFHVUpERHp3nbYcgk/mJzm7t8BNgEXdXitRESkW9thy8Xds8AXO6EuIiJSJkodc3nJzOYDvwI25wvd/dcdUqtu5MPNH7KleQt7VexF74reVCWrKLpTjohIj1RquFQBnwInFJU50OPD5fZXbuehNx4qzCctSVWqispkJdWpaqpT1dSka6hJ1VCVqiqUVSYrqUxWUpGsoCZVQ690L3qle1GVqqIqWVXYR2WyslVZTaqGdFIP/xSRPVupv9DXOMs2TD10KrUDatnQtIGNTRvZ1LyJhkwDjdlG6jP11Gfq2dK8hS2ZLXzW8FmhrCnXRFO2iYZMA47v1DFTliqEVHW6umU6VU1VsorqdHhPVbcKpvx8TSoKu+Jti9dJJ9JqfYnIbin1F/p3wtbfgO7+tdhr1M0M6zeMYf2G7fL27k5DtoHNzZvZ0ryF+kx9IZgas400ZhtpyDTQkG2gvrm+EE7Fr4ZMA/WZejY1b+KT+k8K8w2ZBuqz9WRymZ2qU8IShQCqSbducVUlq6hMFbXKwjr56eKgy7fYatI1helUotTGsoh0Z6X+n/6boukq4Azg/fir0/OYWeHLmOqOOUZzrjkKqBA6xS2q+kw9WzItoVa8zpbMlsI69Zl6NjZtZE12DY2ZlvW2ZLaQ9WzJdalMVha6CPPdgvnuv/yruOWVb20Vv1cnqwvbVSQroleiojCd3086mSZlKbXCRLpAqd1iDxfPm9kDwDMdUiOJXTqRJl2RpndF79j37e405ZoKrap8UBV3B25u3szm5s1bBVZTtqnQOmvMNrKhaUOhxdWQbWl97Ux4tWVYIXxSiVT0t0imC+Ne+fmUpUglil6WIpFIkLQkSUu2bJtIU5kK42WJChKWIJlIRu+WxMwK+0on0qQSqWgfYZ38fDqRJmlJEokEKQtlyZb1E5YgYQkqkhVUJavUVSndzq72URwC7B9nRaR7MrNCS6EPfTrkGM3ZZrZkthS6C/NjWo3ZRpqy0dhVfgwr30rLl+XXyeQyNOeaac41F0KtIdNQKNuc3Uwmlym8sp4lm8uS8xwZzxS2z+QyuzROtrsSligEUjKRjMIvBFsh9JKVUTglkoVQzAdrOpkuhFZxUBaXtw3R/L7aBl6+DmlLtxwrvOeX549THLqGFfbRal9F55QP9+J1DFOwdkOljrlspPWYy4dEz3gR6XDpZJp9kvt0dTUK3J1MLkNTromsZ8nlctG758h5NF0cRvmgynq2sKxtecYzNGej9XOeI0eOXC5XCMj6TDR2ls1lC2GX3z4fmE25psL2+fU2NW+iORsFaPH6+fo3Z5tb1Xt3WokdrW0YGVHgGEYikSBBCKMQZIa1Csfi1qRhOE7OcyQTyUIXa8pShb+/YYVtkpZsVZd84JkZCVqOmU6mWx2juN75FnIykSyUF2+7rff8PyyKW8H5AG+7fuHvURTeZtYqqPPThX9gJNLsV7MfVakq4lRqt9hO96eY2R3AKcDH7j4ylPUDHgKGACuBs939s/AI5Z8Ck4EtwHR3fzFscyHw/bDb69z97lB+NHAX0UjFY8AV7u7bOsbO1l9kW8zCl0gZXhKeD6Z8UOVfxYFXCEhvCbh82OVDKh9YmVwGdy98kbddnm8ZFkI2hLK7k/XsVtsWh3de2327e6G8bWs0P+144Us557moW7ZxA5lcpvAlXLx929B1HPfouIVpci0t5Gxzq/Xy/yDYU9088WYmDJ4Q6z5LbbmcAfzO3deH+T7Ace7+yHY2uwv4d6Lb8+fNAp5y9+vNbFaY/x5wElFX2yHAsUS39z82BMXVQC1Ry2mJmc0PYTEbuAR4nihcJgGPb+cYIrIDCUuQSCbKMji7Wj5k8qGU8xxAIbjzoVgcWPngLISkZwoBn/Vs1D3rLSEGFPaVD/FW00WhWGi95po5tO+hsZ9vqWMuV7v7vPyMu68zs6uBR7a1gbs/bWZD2hRPAY4L03cDi4i++KcA93j013nOzPqY2YFh3SfcfS2AmT0BTDKzRcDe7v5cKL8HOJ0oXLZ1DBGRLmNmpK3nhHapd0Vub71duRhggLt/EKY/BAaE6UHAqqL16kLZ9srr2inf3jG2YmYzzGyxmS1es2bNLpyOiIi0p9RwWWxmN5rZX4fXjcCS3TlwaKV06CU3OzqGu9/q7rXuXrvffvt1ZFVERHqUUsPlH4EmooHyB4EG4LJdON5HobuL8P5xKF8NHFS03uBQtr3ywe2Ub+8YIiLSSUoKF3ff7O6zwr/yj3H3q9x984633Mp8Wh4ydiHwaFH5BRYZB6wPXVsLgBPNrK+Z9QVOBBaEZRvMbFy40uyCNvtq7xgiItJJSgoXM3siXCGWn+9rZgt2sM0DwLPAMDOrM7OLgeuBvzWzt4Avh3mIrvZ6B1gB3AZcChAG8v8FeCG8rs0P7od1bg/bvE00mM92jiEiIp3E8pevbXcls5fcffSOyrqz2tpaX7x4cVdXQ0SkWzGzJe5e27a81DGXnJn9VdHOhtDBg/EiItJ9lXo58f8BnjGz3wMGTABmdFitRESkWyv19i+/NbNaokB5iejHk/UdWC8REenGSr39y9eBK4gu+V0KjCMarD9hO5uJiEgPVeqYyxXAMcC77n48MBpY11GVEhGR7q3UcGlw9wYAM6t09+XArj/bV0REylqpA/p14XcujwBPmNlnwLsdVSkREeneSh3QPyNMXmNmC4F9gN92WK1ERKRb2+k7G7v77zuiIiIiUj5KHXMREREpmcJFRERip3AREZHYKVxERCR2ChcREYmdwkVERGKncBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2ClcREQkdgoXERGJncJFRERip3AREZHYKVxERCR2ChcREYmdwkVERGKncBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2ClcREQkdgoXERGJncJFRERip3AREZHYdUm4mNlKM3vFzJaa2eJQ1s/MnjCzt8J731BuZvYzM1thZi+b2Zii/VwY1n/LzC4sKj867H9F2NY6/yxFRHqurmy5HO/uR7l7bZifBTzl7ocAT4V5gJOAQ8JrBjAbojACrgaOBcYCV+cDKaxzSdF2kzr+dEREJG9P6habAtwdpu8GTi8qv8cjzwF9zOxA4O+AJ9x9rbt/BjwBTArL9nb359zdgXuK9iUiIp2gq8LFgf82syVmNiOUDXD3D8L0h8CAMD0IWFW0bV0o2155XTvlWzGzGWa22MwWr1mzZnfOR0REiqS66LhfdPfVZrY/8ISZLS9e6O5uZt7RlXD3W4FbAWprazv8eCIiPUWXtFzcfXV4/xiYRzRm8lHo0iK8fxxWXw0cVLT54FC2vfLB7ZSLiEgn6fRwMbNeZtY7Pw2cCCwD5gP5K74uBB4N0/OBC8JVY+OA9aH7bAFwopn1DQP5JwILwrINZjYuXCV2QdG+RESkE3RFt9gAYF64OjgF3O/uvzWzF4A5ZnYx8C5wdlj/MWAysALYAlwE4O5rzexfgBfCete6+9owfSlwF1ANPB5eIiLSSSy6oEpqa2t98eLFXV0NEZFuxcyWFP2kpGBPuhRZRETKhMJFRERip3AREZHYKVxERCR2ChcREYmdwkVERGKncBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2ClcREQkdgoXERGJncJFRERip3AREZHYKVxERCR2ChcREYmdwkVERGKncBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2ClcREQkdgoXERGJncJFRERip3AREZHYKVxERCR2ChcREYmdwkVERGKncBERkdgpXEREJHYKFxERiZ3CRUREYqdwERGR2JVtuJjZJDN7w8xWmNmsrq6PiEhPUpbhYmZJ4CbgJOAw4CtmdljX1kpEpOdIdXUFOshYYIW7vwNgZg8CU4DX4j7QczdfQu91r8e9WxGRTrOxzwjGXXpbrPssy5YLMAhYVTRfF8paMbMZZrbYzBavWbOm0yonIlLuyrXlUhJ3vxW4FaC2ttZ3ZR9xp72ISDko15bLauCgovnBoUxERDpBuYbLC8AhZjbUzCqAc4D5XVwnEZEeoyy7xdw9Y2bfBBYASeAOd3+1i6slItJjlGW4ALj7Y8BjXV0PEZGeqFy7xUREpAspXEREJHYKFxERiZ3CRUREYmfuu/TbwbJjZmuAd3dx832BT2KsTnfRE8+7J54z9Mzz7onnDDt/3p9z9/3aFipcYmBmi929tqvr0dl64nn3xHOGnnnePfGcIb7zVreYiIjETuEiIiKxU7jE49aurkAX6Ynn3RPPGXrmeffEc4aYzltjLiIiEju1XEREJHYKFxERiZ3CZTeZ2SQze8PMVpjZrK6uT0cws4PMbKGZvWZmr5rZFaG8n5k9YWZvhfe+XV3XuJlZ0sxeMrPfhPmhZvZ8+LwfCo90KCtm1sfM5prZcjN73cy+UO6ftZl9K/y3vczMHjCzqnL8rM3sDjP72MyWFZW1+9la5Gfh/F82szE7cyyFy24wsyRwE3AScBjwFTM7rGtr1SEywLfd/TBgHHBZOM9ZwFPufgjwVJgvN1cArxfN/wj4N3f/PPAZcHGX1Kpj/RT4rbsPB44kOv+y/azNbBBwOVDr7iOJHtNxDuX5Wd8FTGpTtq3P9iTgkPCaAczemQMpXHbPWGCFu7/j7k3Ag8CULq5T7Nz9A3d/MUxvJPqyGUR0rneH1e4GTu+SCnYQMxsMnAzcHuYNOAGYG1Ypx3PeB/gb4JcA7t7k7uso88+a6PEj1WaWAmqADyjDz9rdnwbWtine1mc7BbjHI88BfczswFKPpXDZPYOAVUXzdaGsbJnZEGA08DwwwN0/CIs+BAZ0Vb06yE+A/w3kwnx/YJ27Z8J8OX7eQ4E1wJ2hO/B2M+tFGX/W7r4auAF4jyhU1gNLKP/POm9bn+1ufb8pXKRkZrYX8DBwpbtvKF7m0TXtZXNdu5mdAnzs7ku6ui6dLAWMAWa7+2hgM226wMrws+5L9K/0ocBAoBdbdx31CHF+tgqX3bMaOKhofnAoKztmliYKlvvc/deh+KN8Mzm8f9xV9esA44HTzGwlUXfnCURjEX1C1wmU5+ddB9S5+/Nhfi5R2JTzZ/1l4C/uvsbdm4FfE33+5f5Z523rs92t7zeFy+55ATgkXFVSQTQIOL+L6xS7MNbwS+B1d7+xaNF84MIwfSHwaGfXraO4+z+5+2B3H0L0uf7O3c8FFgJnhdXK6pwB3P1DYJWZDQtFE4HXKOPPmqg7bJyZ1YT/1vPnXNafdZFtfbbzgQvCVWPjgPVF3Wc7pF/o7yYzm0zUN58E7nD3H3ZtjeJnZl8E/gC8Qsv4w1VE4y5zgL8ielzB2e7edrCw2zOz44DvuPspZnYwUUumH/AScJ67N3Zh9WJnZkcRXcRQAbwDXET0D9Gy/azN7AfANKIrI18Cvk40vlBWn7WZPQAcR3Rb/Y+Aq4FHaOezDUH770RdhFuAi9x9ccnHUriIiEjc1C0mIiKxU7iIiEjsFC4iIhI7hYuIiMRO4SIiIrFTuIiUATM7Ln/nZpE9gcJFRERip3AR6URmdp6Z/cnMlprZL8LzYjaZ2b+F54k8ZWb7hXWPMrPnwrM05hU9Z+PzZvakmf3ZzF40s78Ou9+r6Dks94UfwYl0CYWLSCcxsxFEvwIf7+5HAVngXKIbJS5298OB3xP9ahrgHuB77n4E0d0R8uX3ATe5+5HA/yK6ky9Ed6u+kujZQgcT3R9LpEukdryKiMRkInA08EJoVFQT3SQwBzwU1vkP4NfhuSp93P33ofxu4Fdm1hsY5O7zANy9ASDs70/uXhfmlwJDgGc6/KxE2qFwEek8Btzt7v/UqtDsn9ust6v3ZCq+71UW/f8tXUjdYiKd5yngLDPbHwrPLv8c0f+H+bvvfhV4xt3XA5+Z2YRQfj7w+/Ak0DozOz3so9LMajrzJERKoX/ZiHQSd3/NzL4P/LeZJYBm4DKiB3KNDcs+JhqXgej257eE8MjfnRiioPmFmV0b9jG1E09DpCS6K7JIFzOzTe6+V1fXQyRO6hYTEZHYqeUiIiKxU8tFRERip3AREZHYKVxERCR2ChcREYmdwkVERGL3/wHcaIqKsFAYTwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw(history):\n",
    "    val_acc = np.mean(history.history['val_accuracy'])\n",
    "    print(\"\\n%s: %.2f%%\" % ('val_acc', val_acc*100))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation','train_loss','val_loss'], loc='upper left')\n",
    "\n",
    "    # plt.legend(['train','loss'], loc='upper left')\n",
    "    plt.show()\n",
    "draw(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(filepath+\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(filepath+\"model.json.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df[num_train:].copy().drop(columns=['sales'])\n",
    "test_x = test_x.groupby(['date'],as_index=False).agg(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_buf = df[:num_train].copy().drop(columns=['sales'])\n",
    "train_x_buf = train_x_buf.groupby(['date'],as_index=False).agg(condition)#ok\n",
    "test_x = pd.concat([train_x_buf[-1*(history_input):-1],test_x],ignore_index=True)\n",
    "# print(train_x_buf[-7:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28512, 7, 9)\n"
     ]
    }
   ],
   "source": [
    "test_input = []\n",
    "# for i in range(len(test_x)-history_input+1):\n",
    "#     # test_input.append(test_x[i:i+history_input].values)# show date\n",
    "#     test_input.append(test_x[i:i+history_input].drop(columns=['date']).values)   \n",
    "#     end = x_test_mean.index[x_test_mean['date']==x_test['date'].iloc[i]].tolist()[0]\n",
    "#     start = end - 29\n",
    "#     x_test_input.append(pd.concat([x_test_mean[start:end].drop(columns=[\"date\"]),x_test[i:i+1].drop(columns=[\"date\",\"sales\"])]).values)\n",
    "test_ = df[num_train:].copy()\n",
    "for i in range(len(test_['date'])):\n",
    "    end = test_x.index[test_x['date']==test_['date'].iloc[i]].tolist()[0]\n",
    "    start = end - history_input + 1\n",
    "    test_input.append(pd.concat([test_x[start:end],test_[i:i+1]]).drop(columns=['date','sales']).values)\n",
    "    # print(start,end)\n",
    "    # if i==28511:\n",
    "    #     print(x_test_mean[start:end].drop(columns=[\"date\"]),x_test[i:i+1].drop(columns=[\"date\",\"sales\"]))\n",
    "\n",
    "test_input=np.array(test_input)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.166827 ]\n",
      " [5.1675143]\n",
      " [5.1681614]\n",
      " ...\n",
      " [5.108201 ]\n",
      " [5.108944 ]\n",
      " [5.1100793]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_input)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "print(type(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ProjectPy37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "submit = test_data[['id']]\n",
    "submit['sales'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(filepath+\"submit.csv\",index=False,sep=',')\n",
    "import zipfile\n",
    "with zipfile.ZipFile(filepath+'submit.zip', 'w') as zf:\n",
    "    zf.write(filepath+'submit.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8c472b424fe76d5858727f5e7c739de7bd74a4cb37b6d5f5e59b92d3371aa43"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('DeepLearn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
